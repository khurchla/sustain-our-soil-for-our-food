{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d402f980",
   "metadata": {},
   "source": [
    "# SOIL & FOOD DATA - So what and what now?\n",
    "\n",
    "## Data Sources\n",
    "\n",
    "- **The Global Soil Dataset for Earth System Modeling** Soil Organic Carbon Density dataset at 5 minute resolution\n",
    "    - Land-Atmosphere Interaction Research Group at Sun Yat-sen University\n",
    "        - http://globalchange.bnu.edu.cn/research/soilwd.jsp\n",
    "- **FAOSTAT** Trade: Crops and livestock products | Trade: Detailed trade matrix | Production: Crops and livestock products\n",
    "    - Food and Agriculture Organization of the United Nations\n",
    "        - https://www.fao.org/faostat/en/#data/TCL\n",
    "        - https://www.fao.org/faostat/en/#data/TM\n",
    "        - https://www.fao.org/faostat/en/#data/QCL\n",
    "        \n",
    "## Non-geographical Plotting\n",
    "\n",
    "I'll pull in the dataset I already prepared of Soil Organic Carbon Density, and I'll load the food production and trade datasets to work together with those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83c9702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # view plots inside the notebook\n",
    "# %matplotlib inline  \n",
    "# import package dependencies for environment\n",
    "# import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import plotly.offline as pyo\n",
    "# # Set notebook mode to work in offline\n",
    "# pyo.init_notebook_mode()\n",
    "# import plotly.io as pio\n",
    "# import plotly.figure_factory as ff\n",
    "# import plotly.express as px\n",
    "# import plotly.graph_objects as go # or plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684b21fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the cached variables from earlier SOCD analysis\n",
    "%store -r gdf2flat\n",
    "# # load the unique lists of depths from cache also\n",
    "# %store -r depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d8b164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # write the gdf2flat to csv file for app build with less processing steps\n",
    "# # better for now save it to my hack folder until I can configure storage specific for the app deployment\n",
    "# # commented out because this was superseded by export later of further processed file\n",
    "# gdf2flat.to_csv('/Users/kathrynhurchla/Documents/hack_mylfs_GitHub_projects/gdf2flat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c6499c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # view the top rows in dataframe\n",
    "# gdf2flat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b60d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # drop the extra previous 'index' column, and\n",
    "# # group by depth and count group records with pandas\n",
    "# # shows that there are not records for all depths at all locations; \n",
    "# # with the first depth containing the most\n",
    "# gdf2flat.drop('index', axis=1).groupby('depth').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e20bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only the 4.5 depth records and\n",
    "# reset the index and drop the extra previous index column\n",
    "gdf2flatsurface = gdf2flat[gdf2flat['depth'] == 4.5].reset_index(drop=True)\n",
    "# # view the top rows of result\n",
    "# gdf2flatsurface.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1c17f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick view of resulting geodataframe\n",
    "# for just the surface depth to 4.5cm, whilst\n",
    "# dropping unnecessary previous 'index' column\n",
    "gdf2flatsurface = gdf2flatsurface.drop('index', axis=1)\n",
    "# # view the result\n",
    "# gdf2flatsurface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7b65c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the world dataset from geopandas to get a link of points set \n",
    "# to grab each soil measurement location's country from\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf02945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join my points geometry from gdf2flatsurface to the world and \n",
    "# get the countries they are residing in using a spatial join (sjoin)\n",
    "result = gpd.sjoin(gdf2flatsurface, world, how='left').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833a371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # view all joined column names now\n",
    "# result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd2ee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # view how it looks now with joined columns\n",
    "# # from the looks of it I get some NaN values, but\n",
    "# # for this prototype I'll continue working with it and test how it treats those on a map\n",
    "# result.tail(65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8928d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # count the NaN i.e. null value rows in the joined dataframe\n",
    "# result.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8cc8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # a percent calculation to count the NaN i.e. null value rows or total values in the joined dataframe\n",
    "# 85401/2166784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6e37c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # grab the NaN value rows in a dataframe\n",
    "# result_isna = result[result['index_right'].isna()]\n",
    "# # quick view to confirm it worked as anticipated\n",
    "# # result_isna.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40e16fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot on a map view the NaN rows to see where they appear (rows without a country match in world low res geopandas built in dataset)\n",
    "# result_isna.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5122fb36",
   "metadata": {},
   "source": [
    "### Dropping values off land\n",
    "\n",
    "Mapping the values in the SOCD dataset at surface level (4.5cm depth) which did not match a value in the geopandas world dataset for a correlating country value shows that these are off land location points that appear to be just off the coastal regions of continents, and therefore are more or less irrelevant to our soil story for food production, at least generally speaking. I will drop them for the purposes of this story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97c1fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NaN i.e. null values from the result of linking gdf2flatsurface to add country from world dataset\n",
    "# and drop the extra index column\n",
    "gdf2flatsurfacecountry = result.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ad797c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # what's the count now, as compared to the group done earlier for this depth?\n",
    "# # by counting the first column by index name\n",
    "# gdf2flatsurfacecountry['lon'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1c1821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # view column headers again with just first data row as an example of record values\n",
    "# gdf2flatsurfacecountry.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4fd22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename name column to country_name, in place to replace column name in same column\n",
    "# looks like this worked in results checked but it did return a deprecation :\n",
    "# /Users/kathrynhurchla/opt/anaconda3/envs/envsoil/lib/python3.9/site-packages/pandas/core/frame.py:5039: SettingWithCopyWarning: \n",
    "# A value is trying to be set on a copy of a slice from a DataFrame\n",
    "\n",
    "# See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
    "#   return super().rename(\n",
    "gdf2flatsurfacecountry.rename(columns={\"name\": \"country_name\", \"pop_est\": \"country_pop_est\", \"iso_a3\": \"country_iso_a3\", \"gdp_md_est\": \"country_gdp_md_est\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5b356c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # view the data types of columns to concatenate for URL search\n",
    "# gdf2flatsurfacecountry.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40b3c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # view the top rows of data\n",
    "# gdf2flatsurfacecountry.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85cf2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column that could hold a website URL address for action steps for specific user audience:\n",
    "# where 'country_name' column contains the name of the country where the SOCD soil reading was taken, and\n",
    "# which also correlates to where the food is produced that is exported to audience's chosen country where they eat\n",
    "# aligns with the call to action buttons on wireframe at: https://miro.com/app/board/o9J_lhkKkOA=/\n",
    "\n",
    "# let's come back to this in next sprint, ... see below\n",
    "# # separate the concatenation step to try to avoid a SettingWithCopyWarning in Pandas\n",
    "# learnmoreURL = 'https://www.ecosia.org/soil%20health%20regenerative%20agriculture%20' + gdf2flatsurfacecountry['country_name']\n",
    "# advocateURL = 'https://www.ecosia.org/advocate%20for%20soil%20health%20regenerative%20agriculture%20' + gdf2flatsurfacecountry['country_name']\n",
    "# investURL = 'https://www.ecosia.org/invest%20in%20soil%20health%20regenerative%20agriculture%20' + gdf2flatsurfacecountry['country_name']\n",
    "\n",
    "# ...and use empty string for now to hold the column place\n",
    "learnmoreURL = ''\n",
    "advocateURL = ''\n",
    "investURL = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df2f00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now separately assign the new URL variables to new columns appended to geopandas dataframe\n",
    "# test... do I need to loop over this?\n",
    "gdf2flatsurfacecountry['learnmoreURL'] = learnmoreURL\n",
    "gdf2flatsurfacecountry['advocateURL'] = advocateURL\n",
    "gdf2flatsurfacecountry['investURL'] = investURL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9f84d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # view the end data rows of the result\n",
    "# gdf2flatsurfacecountry.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f838c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a CSV of only the 4.5 depth should the app be too slow or to start with\n",
    "# commented out in lieu of exporting for app the merged file with food trade links later in notebook\n",
    "gdf2flatsurfacecountry.to_csv('/Users/kathrynhurchla/Documents/hack_mylfs_GitHub_projects/gdf2flatsurface.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c8d8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # groupby depth with plotly.io based on example here: https://plotly.com/python/group-by/\n",
    "# # as a test, I'm not really clear what this is showing,\n",
    "# # or if I need to iterate over the records still, e.g. to show a mean\n",
    "# # depths contains array([  4.5       ,   9.10000038,  16.60000038,  28.89999962,\n",
    "# #         49.29999924,  82.90000153, 138.30000305, 229.6000061 ])\n",
    "\n",
    "# depth = depths\n",
    "# SOCD = gdf2flat['SOCD']\n",
    "\n",
    "# data = [dict(\n",
    "#   type = 'scatter',\n",
    "#   x = depth,\n",
    "#   y = SOCD,\n",
    "#   mode = 'markers',\n",
    "#   markersize = 5,\n",
    "#   transforms = [dict(\n",
    "#     type = 'groupby',\n",
    "#     groups = depths,\n",
    "#     styles = [\n",
    "#         dict(target =    4.5       , value = dict(marker = dict(color = 'Set1[1]'))),\n",
    "#         dict(target =    9.10000038, value = dict(marker = dict(color = 'Set1[2]'))),\n",
    "#         dict(target =   16.60000038, value = dict(marker = dict(color = 'Set1[3]'))),\n",
    "#         dict(target =   28.89999962, value = dict(marker = dict(color = 'Set1[4]'))),\n",
    "#         dict(target =   49.29999924, value = dict(marker = dict(color = 'Set1[5]'))),\n",
    "#         dict(target =   82.90000153, value = dict(marker = dict(color = 'Set1[6]'))),\n",
    "#         dict(target =  138.30000305, value = dict(marker = dict(color = 'Set1[7]'))),\n",
    "#         dict(target =  229.6000061 , value = dict(marker = dict(color = 'Set1[8]'))),\n",
    "#     ]\n",
    "#   )]\n",
    "# )]\n",
    "\n",
    "# fig_dict = dict(data=data)\n",
    "# pio.show(fig_dict, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5357d952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check my working directory\n",
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c570c378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # look for the file path of the trade file\n",
    "# !ls ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3449f661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check for the file name of trade file\n",
    "# !ls ../data/Trade_CropsLivestock_E_All_Data_(Normalized)/Trade_Crops_Livestock_E_All_Data_(Normalized).csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cf76fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load in the food trade data from git repository origin directory\n",
    "# dftrade = pd.read_csv('../data/Trade_CropsLivestock_E_All_Data_(Normalized)/Trade_Crops_Livestock_E_All_Data_(Normalized).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1d4617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # view top of the dataframe\n",
    "# dftrade.head()\n",
    "# # unfortunately my git lfs large file storage was shut down and is no longer showing file\n",
    "# # until I can correct that or take the repository off line, I will try to load the file from elsewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f82822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # view the filenames I have in my temporary storage directory for large data files\n",
    "# # since I exceeded the free amount of GitHub large file storage \n",
    "# !ls /Users/kathrynhurchla/Documents/hack_mylfs_GitHub_projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00439668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load in the food trade data copy freshly downloaded from an alternate directory\n",
    "# # adding , encoding = \"ISO-8859-1\" to resolve \"UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe9 in position 158927: invalid continuation byte\"\n",
    "# # alternately use the alias 'latin' for encoding\n",
    "# dftrade = pd.read_csv('/Users/kathrynhurchla/Documents/hack_mylfs_GitHub_projects/Trade_Crops_Livestock_E_All_Data_(Normalized).csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2559dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # view a sample top/bottom of the dataframe\n",
    "# dftrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a55a521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # view the column variables\n",
    "# dftrade.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f102cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# but ideally what I want is to see which country exports to which country, in pairs in a record\n",
    "# load in the food trade detailed matrix copy freshly downloaded from https://www.fao.org/faostat/en/#data/TM to an alternate directory\n",
    "# adding , encoding = \"ISO-8859-1\" to resolve \"UnicodeDecodeError: 'utf-8' codec can't decode byte 0xf4 in position 38698: invalid continuation byte\"\n",
    "# alternately use the alias 'latin' for encoding\n",
    "dftrade_mx = pd.read_csv('/Users/kathrynhurchla/Documents/hack_mylfs_GitHub_projects/Trade_DetailedTradeMatrix_E_All_Data_(Normalized).csv', encoding = \"ISO-8859-1\")\n",
    "# dftrade_mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67df7bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # view a unique list of the element codes/elements\n",
    "# # The input to this function needs to be one-dimensional, so multiple columns will need to be combined.\n",
    "# # select the values and then view them in a flattened numpy array\n",
    "# pd.unique(dftrade_mx[['Element Code','Element']].values.ravel('K'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f96059b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # find the value of Element Code for Export elements\n",
    "# print(str('Export Quantity = Element Code: '))\n",
    "# print(dftrade_mx.loc[dftrade_mx['Element'] == 'Export Quantity', 'Element Code'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4158996e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # view the unique combination of area and area codes\n",
    "# # where 'Area Code' in table is referred to as Country Code (and/or Country Group Code for 5100+) in the Definitions and standards \n",
    "# # on FAO website at https://www.fao.org/faostat/en/#data/QCL\n",
    "# # see the last records which are groupings of countries\n",
    "# # note FAO provides downloadable key file of this Country Code with ISO2, ISO3, and M49 codes for each country\n",
    "# # if I need it for any linkage\n",
    "# dftrade_mx.groupby(['Reporter Country Code','Reporter Countries']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bc63b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for just the 'Export  Quantity' rows by its element code identified earlier\n",
    "dftrade_mx_xq = dftrade_mx[dftrade_mx['Element Code'] == 5910].reset_index(drop=True)\n",
    "# # view first data row of result\n",
    "# dftrade_mx_xq.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e920e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns I do not need\n",
    "dftrade_mx_xq = dftrade_mx_xq.drop('Element Code', axis=1)\n",
    "dftrade_mx_xq = dftrade_mx_xq.drop('Year Code', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d932dfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # view result top data row\n",
    "# dftrade_mx_xq.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff338cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # view the contents of Reporter Country in trade data\n",
    "# dftrade_mx_xq['Reporter Countries'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10acf0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use a boolean to check whether the available reporter and partner countries are the same\n",
    "# dftrade_mx_xq['Reporter Countries'].unique() == dftrade_mx_xq['Partner Countries'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c9fbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # I'd like to see if I can limit the output by year due to the large size of this file, and\n",
    "# # because the most recent year is most valuable to the map portion of the web app at least\n",
    "# # first define groups\n",
    "# groups = dftrade_mx_xq.groupby(['Partner Countries', 'Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97930b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # now use the describe method for summary stats based on the group filter\n",
    "# for key, group in groups:\n",
    "#     print(key)\n",
    "#     print(group.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4420fc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # view the most recent year for each partner country\n",
    "# # group by partner countries, sorted alpha asc, then by year and calculate the max year\n",
    "# maxYear = dftrade_mx_xq.groupby(['Partner Countries'], sort=True).agg(max_Year=('Year', 'max'))\n",
    "# # include a string title\n",
    "# print('Most Recent Year Trade by Partner Countries')\n",
    "# # showing all rows of output with no limit for this statement only\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     # print grouped maxYear defined above\n",
    "#     print(maxYear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f97f540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# commented out due to IndexingError: Unalignable boolean Series provided as indexer \n",
    "# (index of the boolean Series and of the indexed object do not match).\n",
    "# # mask which countries have 2019 as max year\n",
    "# mask = maxYear['max_Year'] == 2019\n",
    "# # show the dataframe excluding the mask rows, \n",
    "# # i.e. only rows with a different max year\n",
    "# dftrade_mx_xq[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4149fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # try another quick and dirty way to see years by just reversing sort\n",
    "# # include a string title\n",
    "# print('Partner Countries with Most Recent Year Trade Not in 2019')\n",
    "# # print grouped maxYear defined above sorted by year asc\n",
    "# # taking head i.e. top rows until I see 2019\n",
    "# print(maxYear.sort_values(['max_Year', 'Partner Countries'], ascending=True).head(23))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9539495d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # of the countries not receiving exports in 2019, \n",
    "# # did any of them record exporting food in 2019?\n",
    "# # again for quick and dirty replace the country group field\n",
    "# # group by reporter countries this time, sorted alpha asc, then by year and calculate the max year\n",
    "# maxExportYear = dftrade_mx_xq.groupby(['Reporter Countries'], sort=True).agg(max_ExportYear=('Year', 'max'))\n",
    "# # include a string title\n",
    "# print('Reporter Countries with Most Recent Year Trade Not in 2019')\n",
    "# # print grouped maxExportYear defined above sorted by year asc\n",
    "# # taking head i.e. top rows until I see 2019\n",
    "# print(maxExportYear.sort_values(['max_ExportYear', 'Reporter Countries'], ascending=True).head(11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f8c189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for my web app I will remove the export quantity trade rows where year is not 2019,\n",
    "# i.e. I will keep only the most recent export dataset available\n",
    "# naming it to a new dataframe whilst resetting index and dropping the previous index\n",
    "dftrade_mx_xq2019 = dftrade_mx_xq.drop(dftrade_mx_xq.loc[dftrade_mx_xq['Year']!=2019].index, inplace=False).reset_index(drop=True) # note False is default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fb42fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # validate my work by viewing the top few rows of reindexed new dataframe\n",
    "# dftrade_mx_xq2019.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86667fe1",
   "metadata": {},
   "source": [
    "### Merge soil carbon data with food trade data\n",
    "\n",
    "Using the partner country code from the trade matrix data as the selection dataset for our app audience member, I want to make that my left table, since the soil organic carbon content measurements will only be relevant when they relate to the audience, i.e. I only need to keep them if were measured in a country which relates to a food exported from that same country and to the country the audience selects as their location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40be9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # review the column variable names in my socd data to find link variable\n",
    "# gdf2flatsurfacecountry.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4853b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # view the contents of country_name\n",
    "# gdf2flatsurfacecountry['country_name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16089970",
   "metadata": {},
   "source": [
    "*At a glance, I expect I could have some that don't match up by name.*\n",
    "\n",
    "Since I'm working today without internet, I'll continue and test what returns null matches for the purposes of this dataset only and resolve from there. It would be best to link on an iso (international standards organization) code 2 or 3, but without the ability to download the FAO key table today, I only have that in one of my two source datasets here I want to link."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2aa248",
   "metadata": {},
   "source": [
    "### Merge soil data with only 2019 trade.\n",
    "\n",
    "I've commented out code cells for all trade, in lieu of merging instead with the new dataframe of only the rows with the most recent year of trade recorded 2019.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b4f1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # using pandas merge function, link the trade matrix and socd dataframes\n",
    "# # with left data as food trade\n",
    "# dftrade_mx_xq_socdsurface = pd.merge(left=dftrade_mx_xq, right=gdf2flatsurfacecountry,\n",
    "#                                      left_on='Reporter Countries',\n",
    "#                                      right_on='country_name',\n",
    "#                                      how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adb1af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # write a CSV of only the 4.5 depth socd merged with food trade data\n",
    "# dftrade_mx_xq_socdsurface.to_csv('/Users/kathrynhurchla/Documents/hack_mylfs_GitHub_projects/dftrade_mx_xq_socdsurface.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0888f1b2",
   "metadata": {},
   "source": [
    "To try to speed up the merge, I'll pull in a key from FAOSTAT to connect its country code with the ISO_3 code in the key. This will allow me to merge on ISO_3 instad of the longer string country names, because ISO_3 is already available in the soil data table which came from the geopandas world dataset along with/when I pulled in the country name from from that standardized source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d089ff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the FAOSTAT key dataset as a variable\n",
    "faoSTATkey = pd.read_csv('/Users/kathrynhurchla/Documents/hack_mylfs_GitHub_projects/FAOSTAT_data_11-26-2021.csv')\n",
    "# # view the top rows\n",
    "# faoSTATkey.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6727615d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For dftrade_mx_xq2019:\n",
    "# using pandas merge function, link the trade matrix reporter country code with key to append its ISO_3 code\n",
    "# with left data as food trade matrix\n",
    "dftrade_mx_xq2019ISO3 = pd.merge(left=dftrade_mx_xq2019, right=faoSTATkey[['Country Code','ISO3 Code']],\n",
    "                                     # key column from left dataframe\n",
    "                                     left_on='Reporter Country Code',\n",
    "                                     # key column from right dataframe\n",
    "                                     right_on='Country Code',\n",
    "                                     # merge as a 'left' join type, and \n",
    "                                     # drop the duplicate key column used for join from right dataframe\n",
    "                                     how='left').drop('Country Code', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec1401a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # are there NaN values in ISO3?\n",
    "# # grab the NaN value rows in a dataframe\n",
    "# dftrade_mx_xq2019ISO3_isna = dftrade_mx_xq2019ISO3[dftrade_mx_xq2019ISO3['ISO3 Code'].isna()]\n",
    "# # # quick view to confirm it worked as anticipated\n",
    "# # dftrade_mx_xq2019ISO3_isna.head()\n",
    "# # view unique list of Reporter Countries with NaN ISO3\n",
    "# dftrade_mx_xq2019ISO3_isna.groupby(['Reporter Country Code','Reporter Countries']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8149350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # view unique Reporter Countries with ISO3 COde\n",
    "# reporterCountries = dftrade_mx_xq2019ISO3.groupby(['Reporter Countries','ISO3 Code']).size()\n",
    "# # showing all rows of output with no limit for this statement only\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     # print grouped variable defined above\n",
    "#     print(reporterCountries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910f4302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is no \"China\" in the trade matrix. I will fill China, mainland with China's ISO3 code 'CHN'\n",
    "# find rows with the Reporter Country Code 41 (for China, mainland), \n",
    "# locate the 'ISO3 Code' column in those rows and set it to 'CHN'\n",
    "dftrade_mx_xq2019ISO3.loc[dftrade_mx_xq2019ISO3['Reporter Country Code'] == 41, 'ISO3 Code'] = 'CHN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c89ed9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename appended ISO3 column to clarify that it's for Reporter Country in trade matrix\n",
    "dftrade_mx_xq2019ISO3.rename(columns={\"ISO3 Code\": \"Reporter Country ISO3\"}, inplace=True)\n",
    "# # check the result\n",
    "# dftrade_mx_xq2019ISO3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb04f758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view number of rows and columns\n",
    "dftrade_mx_xq2019ISO3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17079b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a CSV of only the 2019 export quantity food trade data with ISO3 code appended for Reporter Countries\n",
    "dftrade_mx_xq2019ISO3.to_csv('/Users/kathrynhurchla/Documents/hack_mylfs_GitHub_projects/dftrade_mx_xq2019ISO3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddcf406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # I'm having trouble merging these 472,753 rows so I will try to remove some unnecessary columns\n",
    "# dftrade_mx_xq2019ISO3 = dftrade_mx_xq2019ISO3.drop('Element', axis=1)\n",
    "# dftrade_mx_xq2019ISO3 = dftrade_mx_xq2019ISO3.drop('Year', axis=1)\n",
    "# dftrade_mx_xq2019ISO3 = dftrade_mx_xq2019ISO3.drop('Reporter Country Code', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a812c04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dftrade_mx_xq2019ISO3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a772628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # are there NaN values in ISO3 now, which was renamed?\n",
    "# # grab the NaN value rows in a dataframe\n",
    "# dftrade_mx_xq2019ISO3_isna = dftrade_mx_xq2019ISO3[dftrade_mx_xq2019ISO3['Reporter Country ISO3'].isna()]\n",
    "# # # quick view to confirm it worked as anticipated\n",
    "# # dftrade_mx_xq2019ISO3_isna.head()\n",
    "# # view unique list of Reporter Countries with NaN ISO3\n",
    "# dftrade_mx_xq2019ISO3_isna.groupby(['Reporter Country Code','Reporter Countries']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c933d099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # view unique Reporter Countries with ISO3 Code again now, and we should see China, mainland with CHN included\n",
    "# reporterCountries = dftrade_mx_xq2019ISO3.groupby(['Reporter Countries','Reporter Country ISO3']).size()\n",
    "# # showing all rows of output with no limit for this statement only\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     # print grouped variable defined above\n",
    "#     print(reporterCountries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c10e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Commented out because this is hanging up in the Notebook and may be too large\n",
    "# # I will export the processed file before and merge in a script\n",
    "# # For dftrade_mx_xq2019:\n",
    "# # using pandas merge function, link the trade matrix and socd dataframes\n",
    "# # with left data as food trade\n",
    "# # using as link 'Reporter ISO3 code' and 'country_iso_a3'\n",
    "# # instead of the slow to merge 'Reporter Countries' and 'country_name'\n",
    "# dftrade_mx_xq2019_socdsurface = pd.merge(left=dftrade_mx_xq2019ISO3, right=gdf2flatsurfacecountry,\n",
    "#                                      left_on='Reporter Country ISO3',\n",
    "#                                      right_on='country_iso_a3', \n",
    "#                                      # merge as a 'left' join type, and \n",
    "#                                      # drop the duplicate key column used for join from right dataframe\n",
    "#                                      how='left').drop('country_iso_a3', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2ad30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # view the number or rows and columns of result\n",
    "# dftrade_mx_xq2019_socdsurface.shape()\n",
    "# # view the top data rows of the result\n",
    "# dftrade_mx_xq2019_socdsurface.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c26236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For dftrade_mx_xq2019_socdsurface:\n",
    "# # write a CSV of only the 4.5 depth socd merged with food trade data\n",
    "# dftrade_mx_xq2019_socdsurface.to_csv('/Users/kathrynhurchla/Documents/hack_mylfs_GitHub_projects/dftrade_mx_xq2019_socdsurface.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25841d9",
   "metadata": {},
   "source": [
    "### Plot food export partners matrix\n",
    "\n",
    "Now that I have a dataset showing where food comes from and where it's exported to, see if I can show this visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feba76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Plotly Graph Objects (go), plot lines on a map\n",
    "# based on an example at https://plotly.com/python/lines-on-maps/\n",
    "# world scope with locations by country names (collect an ISO-3 if names doesn't work well, i.e. gaps)\n",
    "# dftrade_mx_xq for paths\n",
    "# see for projection_type options: https://plotly.com/python/reference/layout/geo/#layout-geo-projection-type\n",
    "\n",
    "# fig = go.Figure()\n",
    "\n",
    "# fig.add_trace(go.Scattergeo(\n",
    "#     locationmode = 'country names',\n",
    "#     locations = dftrade_mx_xq['Reporter Countries'],\n",
    "#     hoverinfo = 'text',\n",
    "# #     # string concatenation in pandas for hover text\n",
    "# #     # also a <br> within quotes can put that data on a new line in the hover text optionally\n",
    "# #     text = dftrade_mx_xq['Reporter Countries'].astype(str) + \" exported \" +  dftrade_mx_xq[\"Value\"].astype(str) + \" \" + dftrade_mx_xq[\"Unit\"].astype(str) + \" of \" + dftrade_mx_xq[\"Item\"].astype(str) + \" to \" + dftrade_mx_xq[\"Partner Countries\"].astype(str) + \" in \" + dftrade_mx_xq[\"Year\"].astype(str),\n",
    "#     text = dftrade_mx_xq[\"Item\"]\n",
    "#     mode = 'markers',\n",
    "#     marker = dict(\n",
    "#         size = 2,\n",
    "#         color = 'rgb(255, 0, 0)',\n",
    "#         line = dict(\n",
    "#             width = 3,\n",
    "#             color = 'rgba(68, 68, 68, 0)'\n",
    "#         )\n",
    "#     )))\n",
    "\n",
    "# fig.add_trace(\n",
    "#     go.Scattergeo(\n",
    "#         locationmode = 'country names',\n",
    "# #         hoverinfo = 'text',\n",
    "# #         text = dftrade_mx_xq['Item'],\n",
    "#         mode = 'lines',\n",
    "#         line = dict(width = 1,color = 'red'),\n",
    "#         opacity = 0.5\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# fig.update_layout(\n",
    "#     title_text = 'Food Trade<br>(Hover for item exported)',\n",
    "#     showlegend = False,\n",
    "#     geo = go.layout.Geo(\n",
    "#         scope = 'world',\n",
    "#         projection_type = 'winkel tripel',\n",
    "#         showland = True,\n",
    "#         landcolor = 'rgb(243, 243, 243)',\n",
    "#         countrycolor = 'rgb(204, 204, 204)',\n",
    "#     ),\n",
    "#     height=700,\n",
    "# )\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326ce0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # try with gdf2flatsurface which I have lat long values for\n",
    "# fig = go.Figure()\n",
    "\n",
    "# fig.add_trace(go.Scattergeo(\n",
    "#     locationmode = 'country names',\n",
    "#     locations = dftrade_mx_xq['Reporter Countries'],\n",
    "#     hoverinfo = 'text',\n",
    "# #     # string concatenation in pandas for hover text\n",
    "# #     # also a <br> within quotes can put that data on a new line in the hover text optionally\n",
    "# #     text = dftrade_mx_xq['Reporter Countries'].astype(str) + \" exported \" +  dftrade_mx_xq[\"Value\"].astype(str) + \" \" + dftrade_mx_xq[\"Unit\"].astype(str) + \" of \" + dftrade_mx_xq[\"Item\"].astype(str) + \" to \" + dftrade_mx_xq[\"Partner Countries\"].astype(str) + \" in \" + dftrade_mx_xq[\"Year\"].astype(str),\n",
    "#     text = dftrade_mx_xq[\"Item\"]\n",
    "#     mode = 'markers',\n",
    "#     marker = dict(\n",
    "#         size = 2,\n",
    "#         color = 'rgb(255, 0, 0)',\n",
    "#         line = dict(\n",
    "#             width = 3,\n",
    "#             color = 'rgba(68, 68, 68, 0)'\n",
    "#         )\n",
    "#     )))\n",
    "\n",
    "# fig.add_trace(\n",
    "#     go.Scattergeo(\n",
    "#         locationmode = 'country names',\n",
    "# #         hoverinfo = 'text',\n",
    "# #         text = dftrade_mx_xq['Item'],\n",
    "#         mode = 'lines',\n",
    "#         line = dict(width = 1,color = 'red'),\n",
    "#         opacity = 0.5\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# fig.update_layout(\n",
    "#     title_text = 'Food Trade<br>(Hover for item exported)',\n",
    "#     showlegend = False,\n",
    "#     geo = go.layout.Geo(\n",
    "#         scope = 'world',\n",
    "#         projection_type = 'winkel tripel',\n",
    "#         showland = True,\n",
    "#         landcolor = 'rgb(243, 243, 243)',\n",
    "#         countrycolor = 'rgb(204, 204, 204)',\n",
    "#     ),\n",
    "#     height=700,\n",
    "# )\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7388489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # run through a standalone (within this single cell) test with Dash \n",
    "# # for a web app to build outside of jupyter notebook\n",
    "# import plotly.graph_objects as go # or plotly.express as px\n",
    "# fig = go.Figure() # or any Plotly Express function e.g. px.bar(...)\n",
    "# fig.add_trace( ... )\n",
    "# fig.update_layout( ... )\n",
    "\n",
    "# import dash\n",
    "# import dash_core_components as dcc\n",
    "# import dash_html_components as html\n",
    "\n",
    "# app = dash.Dash()\n",
    "# app.layout = html.Div([\n",
    "#     dcc.Graph(figure=fig)\n",
    "# ])\n",
    "\n",
    "# app.run_server(debug=True, use_reloader=False)  # Turn off reloader if inside Jupyter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envsoil",
   "language": "python",
   "name": "envsoil"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
