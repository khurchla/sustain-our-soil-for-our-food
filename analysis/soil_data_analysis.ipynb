{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88d385fd",
   "metadata": {},
   "source": [
    "# SOIL DATA - Troubles finding what to use?!\n",
    "\n",
    "- SSURGO is more detail can I can work with in the timeframe I need it\n",
    "    - USDA NRCS \n",
    "        - https://sdmdataaccess.nrcs.usda.gov/Default.aspx\n",
    "- STATSGO may be too limiting\n",
    "    - USDA NRCS (shares tables in data source as above)\n",
    "- How about The Global Soil Dataset for Earth System Modeling\n",
    "    - Land-Atmosphere Interaction Research Group at Sun Yat-sen University\n",
    "        - http://globalchange.bnu.edu.cn/research/soilwd.jsp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fba94f0",
   "metadata": {},
   "source": [
    "## Explore Soil Organic Carbon Density in The Global Soil Dataset\n",
    "\n",
    "_I've already done quite a bit of noodling around the USDA data in other notebooks so I'll take a look at whether this one will fit my needs better (and my timeframe and level of pre-aggregation and simplification desired)._\n",
    "\n",
    "### Load the NetCDF \n",
    "\n",
    "Network common data form (NetCDF) is commonly used to store multidimensional geographic data, and especially common with geographic time series data. I'll load the 5 minute geospatial resolution version of the Soil organic carbon density (SOCD5min.zip) NetCDF file in after downloading it from The Global Soil Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081084ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure Google geocoding API key constant/environment variable for work with cesiumpy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55756ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if xarray is not yet installed, uncomment and run one of the following lines (either/or), \n",
    "# which only need to be run once\n",
    "# !pip install xarray\n",
    "# I probably should have used conda because my virtual envelope is maintained with conda, so if I run into problems I will uninstall with pip and reinstall with conda\n",
    "# !conda install xarray "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14683e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if folium is not yet installed, uncomment and run one of the following lines (either/or), \n",
    "# which only need to be run once\n",
    "# !conda install --yes folium -c conda-forge\n",
    "# !pip install --yes folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f82943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view plots inside the notebook\n",
    "%matplotlib inline  \n",
    "# import package dependencies for environment\n",
    "import netCDF4 as nc\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import folium\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas\n",
    "# import fiona to view a full list of supported formats for geopandas.GeoDataFrame.to_file() method\n",
    "import fiona; fiona.supported_drivers\n",
    "# import cesiumpy # commented out due to unresolved AttributeError: partially initialized module 'cesiumpy' has no attribute 'data' (most likely due to a circular import)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e7b587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import more packages for additional plotting tests\n",
    "import geoplot as gplt\n",
    "import geoplot.crs as gcrs\n",
    "import imageio\n",
    "import pathlib\n",
    "import mapclassify as mc\n",
    "from shapely import wkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18533be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check working directory using Shell command in IPython syntax preceded by '!'\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a654953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list directory contents\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1290467f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can I see my data folder in the root directory of my project \n",
    "# (i.e. in the parent of current analysis/notebooks folder working directory)?\n",
    "#!echo ../*/ #alternately\n",
    "!ls .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ffea61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now can I see the files in my data folder?\n",
    "!ls ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fe973a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Great! Now I've checked and copied the filename from right here in my Notebook!\n",
    "# load NetCDF .nc file using the netcdf4 package (note can also be done using gdal package)\n",
    "fn = '../data/SOCD5min.nc' # relative path to netcdf file\n",
    "ds = nc.Dataset(fn) # read as netcdf dataset\n",
    "# view info about the variables\n",
    "print(ds)\n",
    "# print(ds.__dict__) #alternately print metadata as a Python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f008ba1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# access information about the single specific variable metadata (that is not a dimension) \n",
    "# SOCD is Soil Organic Carbon Density\n",
    "# measured and recorded in t/ha (tonnes per hectare)\n",
    "print(ds['SOCD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2797518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just print dimensions as a python dictionary\n",
    "print(ds.dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56ca53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# access the data values just like a numpy array\n",
    "socd = ds['SOCD'][:]\n",
    "print(socd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba04b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "socd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9775875",
   "metadata": {},
   "source": [
    "### Need to get this in a more workable format\n",
    "\n",
    "I'll try to understand this data format more.\n",
    "Ultimately I want to transform it into a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591d05b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the type of the new named variable socd\n",
    "type(socd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6906bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the shape of the array\n",
    "socd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35001ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view an element about midway through\n",
    "socd[0, 1000, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73e01ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try another\n",
    "socd[0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a737e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the non-masked data, specifically by removing rows with all masked data\n",
    "# returns invlid syntax error on the axis=1\n",
    "# socd_unmasked_all = socd[~socd.mask.all[axis=1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f966503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the compressed method will remove masked items, but flattens the result to a 1 dimensional array\n",
    "# so I've lost the location dimensions that way\n",
    "socd_compressed = socd.compressed()\n",
    "print(socd_compressed)\n",
    "socd_compressed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baac9e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the masked array to 2D, to try to make it into a dataframe\n",
    "socd.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb19d33",
   "metadata": {},
   "source": [
    "### Halp!! \n",
    "Here's the point where I asked for help. Xarray to the rescue!\n",
    "Thank you Dr. Larry Gray for your consultation that led me to this pivot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82761a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the xarray package instead of netCDF4 to view and process the dataset from here\n",
    "# added to packages import list at top of notebook\n",
    "# read the data file in with xarray instead and assign it to ds variable\n",
    "ds = xr.open_dataset(\"../data/SOCD5min.nc\")\n",
    "# transform it to a dataframe assigned to df variable\n",
    "df = ds.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c6a1f2",
   "metadata": {},
   "source": [
    "### Yay, no more errors!\n",
    "\n",
    "Now this is what I'm used to data looking like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6630ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4262e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the SOCD column\n",
    "# to better understand the index structure\n",
    "df.SOCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b02cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view all the column variable names in dataframe\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ac522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the index\n",
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44ecf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the unique set of values possible for depth (in centimeters per documentation; 8 levels recorded)\n",
    "depths = df['depth'].unique()\n",
    "depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b936eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the depths variable for use in other notebooks\n",
    "%store depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850e30b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # commented out because it was unnecessary to remove index in order to remove the na values, and\n",
    "# # keep for reference in case I need a different structure to plot something with\n",
    "# # reset the index of the dataframe to remove the hierarchical index structure\n",
    "# df3 = df.reset_index()\n",
    "# # subset by variable name SOCD only the records with SOCD values is na is FALSE, using '~'\n",
    "# df3[~df3.SOCD.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f419270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try the subset to remove na values without going through the flattening of the index first\n",
    "# it works without resetting the index\n",
    "df2 = df[~df.SOCD.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa1efc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the dataframe now, which retains its original indexing, but has only records with values\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525c0274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what's the maximum value that appears for SOCD for any depth\n",
    "df2['SOCD'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d768d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what's the minimum value that appears for SOCD for any depth\n",
    "df2['SOCD'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8de283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see mean for depth\n",
    "df2['SOCD'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b068da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see median for depth\n",
    "df2['SOCD'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3077dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take aggregates of SOCD across all depths, for each location, i.e. when \n",
    "# grouped by the first and second level of the index (i.e. by lon then lat)... \n",
    "# ...is there any relevant aggregate for SOCD which is listed as a % in the documentation? Sum does not seem accurate\n",
    "# skip for now\n",
    "# df2.groupby(level=[0,1]).aggregate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7e021a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the index of the overall df2 dataframe (with NaN removed, before summary)\n",
    "df2flat = df2.reset_index()\n",
    "df2flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcc179c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check max SOCD again now\n",
    "# what's the maximum value that appears for SOCD for any depth\n",
    "df2flat['SOCD'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2870b781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the first 50 rows of the dataframe for instructor/cohort review\n",
    "df2flat.head(50).to_csv(\"../data/SOCD5min_missingvaluesremoved_excerpt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0031db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how much disk use space is in use in data folder, for github large file storage (lfs) considerations\n",
    "# \"*.csv\" and \"*.nc\" are beign logged in git lfs\n",
    "!du -sh ../data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559ce20c",
   "metadata": {},
   "source": [
    "## For mapping, translate to spatial geometry\n",
    "\n",
    "I'll use the GeoPandas package to jump from longitude and latitude columns into a mappable format. In order to try to stay true to the original raw dataset as much as possible, I'll test on the dataframe that includes NA values first to see how GeoPandas handles and displays NA values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b111979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first try this with NA values left in, to stay true to data source as much as possible, and\n",
    "# first flatten the multiple indexes and reset the index, so that lon, lat will be recognized at keys\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bcd2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check this dataframe's columns; lon, lat, and depth have been added to columns with SOCD now\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bd5cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view just the first 24 records\n",
    "df.head(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775d6dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view just the last 10 records\n",
    "df.tail(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750949d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the new index; it's now a sequential index\n",
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b690af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate lon and lat columns into a spatial geometry variable in a GeoPandas dataframe\n",
    "# commented out after initial test run successfully, but as too intensive i.e. slow to run\n",
    "# gdf = geopandas.GeoDataFrame(df, geometry=geopandas.points_from_xy(df.lon, df.lat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89275ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the dataframe with NA removed\n",
    "# translate lon and lat columns into a spatial geometry variable in a GeoPandas dataframe\n",
    "gdf2flat = geopandas.GeoDataFrame(df2flat, geometry=geopandas.points_from_xy(df2flat.lon, df2flat.lat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26e6695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the gdf2flat GeoPandas dataframe with geometry column now\n",
    "gdf2flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358c06a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate lon and lat columns into a spatial geometry variable in a GeoPandas dataframe\n",
    "gdf2flat = geopandas.GeoDataFrame(df2flat, geometry=geopandas.points_from_xy(df2flat.lon, df2flat.lat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f996852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the gdf2sum GeoPandas dataframe with geometry column now\n",
    "gdf2flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c267c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for NaN values in geometry\n",
    "print(gdf2flat['geometry'].isnull().values.any())\n",
    "#check for NaN values in entire dataframe\n",
    "print(gdf2flat['geometry'].isnull().values.all())\n",
    "#count NaN values in geometry\n",
    "print(gdf2flat.isnull().values.any())\n",
    "#count NaN values in entire dataframe\n",
    "print(gdf2flat.isnull().sum().sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4f1728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the data types\n",
    "print(gdf2flat['geometry'].dtype)\n",
    "print(gdf2flat.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb4f80e",
   "metadata": {},
   "source": [
    "### Mapping and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178bcc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making maps with GeoPandas, look at the geometry points for all SOCD\n",
    "# using standard 'pyplot' line style options\n",
    "gdf2flat.plot(marker='*', color='#9b7653', markersize=5); # named 'dirt' color code just looks better than 'brown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad6a4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if gdf2flat has a CRS\n",
    "gdf2flat.crs is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fed7308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a CRS on the geo dataframe object first\n",
    "# according to data source documentation, the coordinate system is WGS_1984\n",
    "# readme file is available at http://globalchange.bnu.edu.cn/download/doc/worldsoil/readme.zip\n",
    "gdf2flat.crs = \"EPSG:4326\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44919740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the crs now\n",
    "gdf2flat.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302f1a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the built in world natural earth low resolution dataset\n",
    "world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\n",
    "\n",
    "#check if it has a CRS\n",
    "print(world.crs is None)\n",
    "world.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437d75c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check CRS --Before combining maps, however, remember to always ensure they share a common CRS (so they will align).\n",
    "# no need to convert because they match\n",
    "# gdf2flat = gdf2flat.to_crs(world.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadfb2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot points on the built in world map\n",
    "base = world.plot(color='white', edgecolor='black')\n",
    "gdf2flat.plot(ax=base, marker='o', color='#9b7653', markersize=1); # named 'dirt' color code just looks better than 'brown'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112f6115",
   "metadata": {},
   "source": [
    "### Export data to a Spatial file format\n",
    "\n",
    "Using Geopandas I will export to a GeoJSON file to upload data to work in Cesium ion/Cesium Story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c1ced4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export gdf2flat to GeoJSON\n",
    "# gdf2flat.to_file(\"../data/gdf2flat.geojson\", driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33209757",
   "metadata": {},
   "source": [
    "### More mapping trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5f1386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using geoplot package to plot the points on the same world map\n",
    "ax = gplt.polyplot(world, edgecolor='black')\n",
    "gplt.pointplot(gdf2flat, ax=ax, marker='o', color='#9b7653')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f04b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check geometry of base and its coordinate reference system (crs) (...and possibly did this earlier already)\n",
    "print(world.geometry)\n",
    "print(world.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f66b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to explicitly set the geometry even though it appears to already be there\n",
    "world = world.set_geometry(\"geometry\")\n",
    "world.geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a1dd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check geometry of gdf2flat and its crs also\n",
    "print(gdf2flat.geometry)\n",
    "print(gdf2flat.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a7402b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to explicitly set the geometry of gdf2flat even though it appears to already be there\n",
    "gdf2flat = gdf2flat.set_geometry(\"geometry\")\n",
    "gdf2flat.geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d753549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using shapely import wkt convert the column geometry to actual geometries \n",
    "# (I think it was already reading as geometry before this, but this is a test of a recommended debugging solution for \"ValueError: The input GeoDataFrame does not have a \"geometry\" column set.\")\n",
    "# commented out test as failed (which is good actually) with \"TypeError: Only str is accepted.\" indicating \n",
    "# my geometry was not strings but actually already geometry\n",
    "# gdf2flat['geometry'] = gdf2flat['geometry'].apply(wkt.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b123a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through dataframe to validate for any invalid geometries\n",
    "for index, row in gdf2flat.iterrows():\n",
    "    geom = row['geometry']\n",
    "    if len(geom.coords) != 1:\n",
    "          print(\"This row has an invalid point geometry\")\n",
    "          # this is just one example of invalid geometries, there may be others, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4814c576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check geometry as a GeoSeries for missing values\n",
    "gdf2flat[\"geometry\"].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04baa3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check geometry as a GeoSeries for empty geometries\n",
    "gdf2flat[\"geometry\"].is_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f122d22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect only those where FALSE (i.e. only valid instances) in either case (or |) using a mask\n",
    "gdf2flat_invalids = gdf2flat[\"geometry\"][~(gdf2flat[\"geometry\"].is_empty | gdf2flat[\"geometry\"].isna())]\n",
    "gdf2flat_invalids # matching length of gdf2flat confirms no invalid entries were found and removed       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541a5586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use magic store command to cache variable to read it from other Jupyter Notebooks\n",
    "# to read it into another notebook, use %store -r gdf2flat\n",
    "%store gdf2flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad381df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envsoil",
   "language": "python",
   "name": "envsoil"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
