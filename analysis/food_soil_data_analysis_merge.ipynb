{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "# import native python garbage collector to explicitly invoke it\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw data file is not saved in repo, and can be downloaded as a zip file from its source:\n",
    "# http://globalchange.bnu.edu.cn/research/soilwd.jsp \"Soil organic carbon density: SOCD5min.zip\"\n",
    "# read the data file in with xarray and assign it to ds variable\n",
    "DS = xr.open_dataset(\"./data/SOCD5min.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform it to a dataframe assigned to df variable\n",
    "df = DS.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try the subset to remove na values without going through the flattening of the index first\n",
    "# it works without resetting the index first\n",
    "# flatten the index of the overall dataframe (after NaN removed, before summary) in place so it persists\n",
    "# DO NOT DROP THE INDEX HERE! Flatten the multi-level index, and keep all levels as columns\n",
    "df1 = df[~df.SOCD.isna()].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.index.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only the 4.5 depth records and\n",
    "# reset the index and drop the extra previous index column\n",
    "df2 = df1[df1['depth'] == 4.5].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.index.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the dataframe with NA removed\n",
    "# translate lon and lat columns into a spatial geometry variable in a GeoPandas dataframe, and\n",
    "# set a CRS on the geo dataframe object according to data source documentation,\n",
    "# readme file is available at http://globalchange.bnu.edu.cn/download/doc/worldsoil/readme.zip\n",
    "gdf = gpd.GeoDataFrame(df2, geometry=gpd.points_from_xy(df2['lon'], df2['lat']), crs=\"EPSG:4326\")\n",
    "# gdf.crs = \"EPSG:4326\" # moved above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.index.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the world dataset from geopandas to do a spatial link/merge with on points geometry which is a shapely series\n",
    "# to grab each soil measurement location's country from\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.index.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join my geometry from gdf2flatsurface to the world and\n",
    "# get the countries they are residing in using a spatial join (sjoin)\n",
    "gdf1 = gpd.sjoin(gdf, world, how='left').reset_index(drop=True)\n",
    "# print(gdf.head())\n",
    "#del world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf1.index.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename name column to country_name, in place to replace column name in same column, and\n",
    "# rename other columns for clarity after they are merged with food trade data later\n",
    "gdf1.rename(columns={\n",
    "    \"continent\": \"Reporter_Country_continent\",\n",
    "    \"name\": \"Reporter_Country_name\",\n",
    "    \"pop_est\": \"Reporter_Country_pop_est\",\n",
    "    \"iso_a3\": \"Reporter_Country_ISO3\",\n",
    "    \"gdp_md_est\": \"Reporter_Country_gdp_md_est\",\n",
    "    \"lon\": \"Reporter_Country_lon\",\n",
    "    \"lat\": \"Reporter_Country_lat\",\n",
    "    \"SOCD\": \"Reporter_Country_SOCD_depth4_5\"\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NaN i.e. null values from the result of linking gdf to add country from world dataset\n",
    "# plotting those locations showed they are off land in water areas\n",
    "# and drop the extra index column\n",
    "gdf2 = gdf1.dropna().reset_index(drop=True)\n",
    "# print(gdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf2['Reporter_Country_lon'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns I no longer need from soil data to limit size\n",
    "gdf3 = gdf2.drop(['geometry', 'index_right', 'depth'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf3.index.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try converting geopandas dataframe back to standard pandas dataframe before more processing\n",
    "df3 = pd.DataFrame(gdf3)\n",
    "# check variable object type that should now be a <class 'pandas.core.frame.DataFrame'>\n",
    "type(df3)\n",
    "# then view the data types of the column series to see if any of them are still holding onto geopandas.array type\n",
    "df3.dtypes\n",
    "# del gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[df3['Reporter_Country_SOCD_depth4_5'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a unique list of the stats from the soil data for countries, to append to food data for food chart\n",
    "# whilst converting geopandas dataframe back to standard pandas dataframe before more processing\n",
    "# removed 'SOCDcountryMean' because of errors noted above\n",
    "CntryStats = pd.DataFrame(df3, columns=[\n",
    "    'Reporter_Country_continent', 'Reporter_Country_name',\n",
    "    'Reporter_Country_ISO3', 'Reporter_Country_gdp_md_est',\n",
    "    'Reporter_Country_pop_est'\n",
    "    ]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CntryStats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write intermittent full on land soil dataset of 4.5 cm depth to file for peripheral charts, e.g. bar chart\n",
    "df3.to_csv(\"./data/dfsoil.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the food trade detailed matrix copy freshly downloaded\n",
    "# from https://www.fao.org/faostat/en/#data/TM to an alternate directory\n",
    "# adding , encoding = \"ISO-8859-1\" to resolve \"UnicodeDecodeError:\n",
    "# 'utf-8' codec can't decode byte 0xf4 in position 38698: invalid continuation byte\"\n",
    "# alternately use the alias 'latin' for encoding\n",
    "tr = '/Users/kathrynhurchla/Documents/hack_mylfs_GitHub_projects/Trade_DetailedTradeMatrix_E_All_Data_(Normalized).csv'\n",
    "dffood = pd.read_csv(tr, encoding=\"ISO-8859-1\")\n",
    "# del tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for just the 'Export  Quantity' rows by its element code identified earlier\n",
    "dffood1 = dffood[dffood['Element Code'] == 5910].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename Value to explicitly specify the type of value, \n",
    "# because I will drop Element column which is now only 'Export Quantity'\n",
    "# and also drop Unit which is now all 'tonnes' (and will be labelled in plots clearly)\n",
    "dffood1.rename(columns={\"Value\": \"Export_Quantity_2019_Value_tonnes\",\n",
    "                       \"Reporter Country Code\": \"Reporter_Country_Code\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffood1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for my web app I will remove the export quantity trade rows where year is not 2019,\n",
    "# i.e. I will keep only the most recent export dataset available\n",
    "# naming it to a new dataframe whilst resetting index and dropping the previous index\n",
    "dffood2 = dffood1.drop(dffood1.loc[dffood1['Year'] != 2019].index,\n",
    "                     inplace=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffood2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns from food trade data that I do not need anymore\n",
    "dffood3 = dffood2.drop(['Element Code',\n",
    "                        'Element',\n",
    "                        'Year Code',\n",
    "                        'Unit',\n",
    "                        'Item Code'], axis=1\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffood3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffood3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the FAOSTAT key dataset as a variable (reusing ds)\n",
    "DS1 = pd.read_csv('/Users/kathrynhurchla/Documents/hack_mylfs_GitHub_projects/FAOSTAT_data_11-26-2021.csv')\n",
    "# rename the country code column to match exactly for merging easier\n",
    "DS1.rename(columns={\"Country Code\": \"Reporter_Country_Code\", \"ISO3 Code\": \"Reporter_Country_ISO3\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS1.index.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS1.Reporter_Country_ISO3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for my web app I will remove the export quantity trade rows where year is not 2019,\n",
    "# i.e. I will keep only the most recent export dataset available\n",
    "# naming it to a new dataframe whilst resetting index and dropping the previous index\n",
    "dffood4 = dffood3.drop(dffood3.loc[dffood3['Year'] != 2019].index,\n",
    "                       inplace=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffood4.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffood5 = dffood3.drop(['Year'], axis=1\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For dffood:\n",
    "# using pandas merge function, link the trade matrix **reporter country** code with key to append its ISO_3 code,\n",
    "# not necessary to do this for the partner country because I do not intend to connect that with food trade data\n",
    "# with left data as food trade matrix\n",
    "dffood6 = dffood5.merge(DS1[['Reporter_Country_Code', 'Reporter_Country_ISO3']],\n",
    "                        # left on key column that exists with same name now in both dataframes\n",
    "                        how='left',\n",
    "                        on='Reporter_Country_Code',\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffood6.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename a few more columns to align across datasets for clarity\n",
    "dffood6.rename(columns={\"Reporter Countries\": \"Reporter_Country_name\",\n",
    "                        \"Partner Countries\": \"Partner_Country_name\"}, inplace=True\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffood6.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is no \"China\" in the food trade matrix. I will fill China, mainland with China's ISO3 code 'CHN'\n",
    "# find rows with the Reporter Country Code 41 (for China, mainland), \n",
    "# locate the 'ISO3 Code' column in those rows and set it to 'CHN'\n",
    "dffood6.loc[dffood6['Reporter_Country_Code'] == 41, 'Reporter_Country_ISO3'] = 'CHN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit for scale to US partners in food dataset\n",
    "USTradePartners = dffood6[dffood6['Partner Country Code'].isin([231, 232, 240])] \n",
    "                    \n",
    "USTradePartners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USTradePartners1 = USTradePartners['Reporter_Country_ISO3'].unique()\n",
    "USTradePartners1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(9*18)-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take subset of soil dataframe for only those reporter countries exporting food items to US\n",
    "df_subUS = df3.loc[df3['Reporter_Country_ISO3'].isin(USTradePartners1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subUS.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to expand scale to both USA and China partners in food dataset\n",
    "USCNTradePartners = dffood6[dffood6['Partner Country Code'].isin([41, 96, 128, 214, 351])]\n",
    "USCNTradePartners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USCNTradePartners1 = USCNTradePartners['Reporter_Country_ISO3'].unique()\n",
    "USCNTradePartners1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(9*18)-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take subset of soil dataframe for only those reporter countries exporting food items to US or China\n",
    "df_subUSCN = df3.loc[df3['Reporter_Country_ISO3'].isin(USCNTradePartners1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subUSCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write dataframes to file in case the kernel chokes on memory again from this point on\n",
    "df_subUS.to_csv('./data/dfsoil_subUS.csv')\n",
    "df_subUSCN.to_csv('./data/dfsoil_subUSCN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns I do not need anymore\n",
    "dffood7 = dffood6.drop(['Reporter_Country_Code', 'Partner Country Code'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with left data as full 2019 food trade matrix, merge in unique country stats, for peripheral charts of at risk foods\n",
    "dffood8 = dffood7.merge(CntryStats,\n",
    "                        # left on key that exists with same name now in both dataframes\n",
    "                        how='left',\n",
    "                        on='Reporter_Country_ISO3'\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write dataframe to file in case the kernel chokes on memory again from this point on\n",
    "dffood8.to_csv('./data/dffood.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffood8.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the list of variable objects in memory with\n",
    "[dir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selectively delete things I saved that I no longer need from within this script.\n",
    "# Keep all '__...__' globals and aliases for packages unless I am done with them\n",
    "# (it runs periodically otherwise to release unreferenced memory)\n",
    "# review list of tracked object (generation=None) (generation=0) (generation=1) (generation=2)\n",
    "gc.get_objects(generation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "del [CntryStats,\n",
    "     DS,\n",
    "     DS1,\n",
    "     USCNTradePartners,\n",
    "     USCNTradePartners1,\n",
    "     USTradePartners,\n",
    "     USTradePartners1,\n",
    "     df,\n",
    "     df1,\n",
    "     df2,\n",
    "     df3,\n",
    "     dffood,\n",
    "     dffood1,\n",
    "     dffood2,\n",
    "     dffood3,\n",
    "     dffood4,\n",
    "     dffood5,\n",
    "     dffood6,\n",
    "     dffood7,\n",
    "     gdf,\n",
    "     gdf1,\n",
    "     gdf2,\n",
    "     gdf3,\n",
    "     gpd,\n",
    "     nc,\n",
    "     tr,\n",
    "     world,\n",
    "     xr\n",
    "    ]\n",
    "     \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release selected memory\n",
    "gc.collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the list of variable objects in memory with\n",
    "[dir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df_subUS' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store df_subUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df_subUSCN' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store df_subUSCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'dffood8' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store dffood8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_subUSCN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yl/cmk7gt492252lhxv4dwq5q280000gn/T/ipykernel_11959/1054215897.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_subUSCN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_subUSCN' is not defined"
     ]
    }
   ],
   "source": [
    "df_subUSCN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pandas merge US food dataset with soil filtered for only US partners\n",
    "# df_subUS1 = dffood8.merge(df_subUS,\n",
    "#                          how='inner',\n",
    "#                          on='Reporter_Country_ISO3'\n",
    "#                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if merge works, print a concise summary of the resulting dataframe\n",
    "print(df_subUS1.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a CSV of merged US partner 4.5 depth socd merged with food trade data to the data folder in project directory\n",
    "df_subUS1.to_csv(\"./data/df_subUS1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del df_subUS\n",
    "# del df_subUS1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pandas merge North American food dataset with soil filtered for only NA partners\n",
    "# df_subUSCN1 = dffood8.merge(df_subUSCN,\n",
    "#                             how='inner',\n",
    "#                             on='Reporter_Country_ISO3'\n",
    "#                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if merge works, print a concise summary of the resulting dataframe\n",
    "print(df_subUSCN1.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # write a CSV of merged NA partner 4.5 depth socd merged with food trade data to the data folder in project directory\n",
    "# df_subUSCN1.to_csv(\"./data/df_subUSCN1.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envsoil",
   "language": "python",
   "name": "envsoil"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
